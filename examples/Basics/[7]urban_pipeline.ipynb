{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Pipeline Basics\n",
    "\n",
    "Welcome to this Basics notebook on the `UrbanPipeline` ðŸ‘‹ classâ€”a cracking little tool in UrbanMapper that lets you bundle up all your workflow steps into one neat package.\n",
    "\n",
    "In this notebook, weâ€™ll:\n",
    "\n",
    "- Get to grips with what the `UrbanPipeline` does.\n",
    "- Build a simple pipeline with a few key steps.\n",
    "- Run it and show off the results.\n",
    "- Save the pipeline, load it back, and use the enriched layer for machine learning analysis.\n",
    "\n",
    "Letâ€™s get started! ðŸŒŸ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_mapper as um\n",
    "from urban_mapper.pipeline import UrbanPipeline\n",
    "\n",
    "mapper = um.UrbanMapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whatâ€™s the `UrbanPipeline` All About?\n",
    "\n",
    "The `UrbanPipeline` class is like the conductor of an orchestra â€“â€“ for the ML enthusiasts, it is trying to mimic what Scikit-Learn does with the Scikit Pipeline â€“â€“ â€”it brings together all the UrbanMapper steps (loading data, creating layers, imputing missing bits, filtering, enriching, and visualising) and makes them play in harmony. You define your steps, pop them into the pipeline, and it handles the rest. Itâ€™s brilliant for keeping your workflow tidy and repeatable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Simple Pipeline\n",
    "\n",
    "Letâ€™s build a pipeline that does the following:\n",
    "\n",
    "- Loads PLUTO data from a CSV file.\n",
    "- Creates a street intersections layer for Manhattan.\n",
    "- Imputes missing coordinates.\n",
    "- Filters data to the layerâ€™s bounding box.\n",
    "- Enriches the layer with average building floors.\n",
    "- Sets up an interactive map to visualise it all.\n",
    "\n",
    "Weâ€™ll define each step and slot them into our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_layer = (\n",
    "    mapper.urban_layer.with_type(\"streets_intersections\")\n",
    "    .from_place(\"Manhattan, New York City, USA\", network_type=\"drive\")\n",
    "    .with_mapping(\n",
    "        longitude_column=\"longitude\",\n",
    "        latitude_column=\"latitude\",\n",
    "        output_column=\"nearest_intersection\",\n",
    "        threshold_distance=50,  # Optional: sets a 50-meter threshold for nearest mapping.\n",
    "        # Distance unit is based on the coordinate reference system, see further in the documentation.\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "loader = (\n",
    "    mapper.loader\n",
    "    .from_file(\"./pluto.csv\")\n",
    "    .with_columns(\"longitude\", \"latitude\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "imputer = (\n",
    "    mapper.imputer.with_type(\"SimpleGeoImputer\")\n",
    "    .on_columns(\"longitude\", \"latitude\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "filter_step = mapper.filter.with_type(\"BoundingBoxFilter\").build()\n",
    "\n",
    "enricher = (\n",
    "    mapper.enricher.with_data(group_by=\"nearest_intersection\", values_from=\"numfloors\")\n",
    "    .aggregate_by(method=\"mean\", output_column=\"avg_floors\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "visualiser = (\n",
    "    mapper.visual.with_type(\"Interactive\")\n",
    "    .with_style({\"tiles\": \"CartoDB dark_matter\"})\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Assemble the pipeline\n",
    "# Note that a step is a tuple with a name and the step itself.\n",
    "pipeline = UrbanPipeline(\n",
    "    [\n",
    "        (\"urban_layer\", urban_layer),\n",
    "        (\"loader\", loader),\n",
    "        (\"imputer\", imputer),\n",
    "        (\"filter\", filter_step),\n",
    "        (\"enricher\", enricher),\n",
    "        (\"visualiser\", visualiser)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Note that we can do this in a more concise way, but we are showing the steps for clarity.\n",
    "# The concise way would be looking alike this for only with urban layer:\n",
    "\n",
    "# pipeline = UrbanPipeline([\n",
    "#     (\"urban_layer\", (\n",
    "#         mapper.urban_layer\n",
    "#         .with_type(\"streets_intersections\")\n",
    "#         .from_place(\"Downtown Brooklyn, New York City, USA\", network_type=\"drive\")\n",
    "#         .with_mapping(\n",
    "#             longitude_column=\"longitude\",\n",
    "#             latitude_column=\"latitude\",\n",
    "#             output_column=\"nearest_intersection\",\n",
    "#             threshold_distance=50\n",
    "#         )\n",
    "#         .build()\n",
    "#     )),\n",
    "#     # Add the other steps here\n",
    "# ])\n",
    "\n",
    "# Let's preview our urban pipeline workflow\n",
    "pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "Time to put it to work! Weâ€™ll use `compose_transform` to run the entire pipeline in one goâ€”loading, imputing, filtering, mapping, enriching, all sorted. Then, weâ€™ll visualise the results with a snazzy interactive map.\n",
    "\n",
    "Note however that we could do this in two steps, first calling `compose()` and then `transform()`, but we are showing the two steps in one for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline\n",
    "mapped_data, enriched_layer = pipeline.compose_transform()\n",
    "\n",
    "# Show the results\n",
    "fig = pipeline.visualise(result_columns=[\"avg_floors\"])\n",
    "# result_columns is basically the columns that will be displayed in the map.\n",
    "# If you want to display only one column, you can pass a string as well.\n",
    "\n",
    "fig  # Displays an interactive map in your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Your Pipeline\n",
    "\n",
    "You can save your pipeline to a file and load it back later (that means every you would need the pipeline, it won't need to redo its entire workflow as saved). Here, weâ€™ll save it, load it, and ensure itâ€™s ready for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save(\"./my_pipeline.dill\")\n",
    "\n",
    "loaded_pipeline = UrbanPipeline.load(\"./my_pipeline.dill\")\n",
    "\n",
    "loaded_pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Enriched Layer for Machine Learning Analysis\n",
    "\n",
    "Now, letâ€™s retrieve the enriched urban layer using `.get_layer()` for machine learning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_layer = loaded_pipeline.get_step(\"urban_layer\")\n",
    "\n",
    "enriched_gdf = enriched_layer.get_layer()\n",
    "\n",
    "enriched_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceeding with Machine Learning Analysis\n",
    "\n",
    "With the enriched layer in hand, letâ€™s perform a simple machine learning task. Weâ€™ll use K-Means clustering to group street intersections based on the average number of building floors (`avg_floors`).\n",
    "\n",
    "### Step 1: Prepare the Data\n",
    "\n",
    "Extract the relevant feature from the enriched layer and handle any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = enriched_gdf[['avg_floors']]\n",
    "\n",
    "features = features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply K-Means Clustering\n",
    "\n",
    "Cluster the intersections into 3 groups based on `avg_floors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(features)\n",
    "\n",
    "enriched_gdf['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualise the Clusters\n",
    "\n",
    "Visualise the clusters on a static map using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the cluster centroids (average floors for each cluster) and flatten to 1D\n",
    "centroids = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "# Get the indices that would sort the centroids from low to high\n",
    "sorted_indices = np.argsort(centroids)\n",
    "\n",
    "# Create a mapping from original cluster labels to new sorted labels\n",
    "label_mapping = {original: new for new, original in enumerate(sorted_indices)}\n",
    "\n",
    "# Apply the mapping to the GeoDataFrame to create sorted cluster labels\n",
    "enriched_gdf['cluster_sorted'] = enriched_gdf['cluster'].map(label_mapping)\n",
    "\n",
    "# Round the sorted centroids for display in the legend\n",
    "rounded_centroids = [round(centroids[idx], 1) for idx in sorted_indices]\n",
    "\n",
    "# Set up the figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the GeoDataFrame using the sorted cluster labels and 'viridis' colormap\n",
    "scatter = enriched_gdf.plot(column='cluster_sorted', ax=ax, cmap='viridis')\n",
    "\n",
    "# Label the axes and set the title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.title('Street Intersections in Manhattan Clustered by Average Building Floors')\n",
    "\n",
    "# Add a color bar to the plot\n",
    "cbar = scatter.get_figure().colorbar(scatter.get_children()[0], ax=ax)\n",
    "\n",
    "# Set the ticks and labels for the color bar based on the sorted centroids\n",
    "cbar.set_ticks(range(len(sorted_indices)))\n",
    "cbar.set_ticklabels([f'Avg. Floors: {centroid}' for centroid in rounded_centroids])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to JupyterGIS (Optional)\n",
    "\n",
    "For collaborative exploration, you can export your pipeline to JupyterGIS. Check out [JupyterGIS documentation](https://github.com/geojupyter/jupytergis) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_jgis(\n",
    "    filepath=\"urban_analysis.JGIS\",\n",
    "    urban_layer_name=\"Manhattan Intersections\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping It Up\n",
    "\n",
    "Smashing job! ðŸŒŸ Youâ€™ve built and run your first `UrbanPipeline`, saved it, loaded it back, retrieved the enriched layer, and performed a machine learning analysis. You can now reuse, share, or tweak this workflow as needed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
