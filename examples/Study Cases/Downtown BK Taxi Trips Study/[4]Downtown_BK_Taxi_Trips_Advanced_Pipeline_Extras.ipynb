{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downtown Brooklyn Taxi Trips Study - Advanced Pipeline\n",
    "This notebook analyzes taxi trips with multiple enrichments. Similar to [3].  The extras are simply that we leverages \"custom_function\" from the enricher module to compute more from the Taxis dataset. See further below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "\n",
    "# ⚠️ INFORMATION ABOUT THE CURRENT CELL ⚠️\n",
    "# The following shows custom aggregation functions \n",
    "# used later on in the pipeline\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def most_common_payment(series):\n",
    "    if series.empty:\n",
    "        return None\n",
    "    mode = series.mode()\n",
    "    return mode.iloc[0] if not mode.empty else None\n",
    "\n",
    "def peak_pickup_hour(series):\n",
    "    if series.empty:\n",
    "        return None\n",
    "    if not pd.api.types.is_datetime64_any_dtype(series):\n",
    "        try:\n",
    "            series = pd.to_datetime(series)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not convert series to datetime: {e}\")\n",
    "    hours = series.dt.hour\n",
    "    mode = hours.mode()\n",
    "    return mode.iloc[0] if not mode.empty else None\n",
    "\n",
    "def peak_dropoff_hour(series):\n",
    "    if series.empty:\n",
    "        return None\n",
    "    if not pd.api.types.is_datetime64_any_dtype(series):\n",
    "        try:\n",
    "            series = pd.to_datetime(series)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Could not convert series to datetime: {e}\")\n",
    "    hours = series.dt.hour\n",
    "    mode = hours.mode()\n",
    "    return mode.iloc[0] if not mode.empty else None\n",
    "\n",
    "def average_trip_distance(series):\n",
    "    return series.mean() if not series.empty else 0\n",
    "\n",
    "def average_fare_amount(series):\n",
    "    return series.mean() if not series.empty else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of preprocessed payment_type:\n",
      "0    Credit card\n",
      "1    Credit card\n",
      "2           Cash\n",
      "3           Cash\n",
      "4           Cash\n",
      "Name: payment_type, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#####################################################################################\n",
    "\n",
    "# ⚠️ INFORMAITON ABOUT THE CURRENT CELL ⚠️\n",
    "# Some data wrangling are necessary due to the raw data being not\n",
    "# computable enough hence the \"manual\" load to create a pre-processed\n",
    "# version of the dataset\n",
    "\n",
    "#####################################################################################\n",
    "\n",
    "import geopandas as gpd\n",
    "from urban_mapper import ParquetLoader\n",
    "\n",
    "# Define the payment type mapping\n",
    "# Dictionary found @ https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "payment_type_mapping = {\n",
    "    1: 'Credit card',\n",
    "    2: 'Cash',\n",
    "    3: 'No charge',\n",
    "    4: 'Dispute',\n",
    "    5: 'Unknown',\n",
    "    6: 'Voided trip'\n",
    "}\n",
    "\n",
    "# Load the parquet file\n",
    "file_path = \"./taxisvis5M.parquet\"\n",
    "df = ParquetLoader(file_path, \"pickup_latitude\", \"pickup_longitude\")._load_data_from_file()\n",
    "\n",
    "# Apply the mapping to the payment_type column\n",
    "df['payment_type'] = df['payment_type'].map(payment_type_mapping)\n",
    "\n",
    "# Optional: Verify the preprocessing\n",
    "print(\"Sample of preprocessed payment_type:\")\n",
    "print(df['payment_type'].head())\n",
    "\n",
    "df.to_parquet(\"./taxisvis5M_preprocessed.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sgp28/Desktop/Delivery/NYU/UrbanMapper/.venv/lib/python3.10/site-packages/osmnx/convert.py:542: FutureWarning: <class 'geopandas.array.GeometryArray'>._reduce will require a `keepdims` parameter in the future\n",
      "  dupes = edges[mask].dropna(subset=[\"geometry\"])\n"
     ]
    }
   ],
   "source": [
    "import urban_mapper as um\n",
    "from urban_mapper.pipeline import UrbanPipeline\n",
    "\n",
    "# Initialise UrbanMapper\n",
    "mapper = um.UrbanMapper()\n",
    "\n",
    "# Build urban layer for street segments\n",
    "urban_layer = (\n",
    "    mapper.urban_layer\n",
    "    .with_type(\"streets_roads\")\n",
    "    .from_place(\"Downtown Brooklyn, New York City, USA\", network_type=\"drive\")\n",
    "    .with_mapping(\n",
    "        longitude_column=\"pickup_longitude\",\n",
    "        latitude_column=\"pickup_latitude\",\n",
    "        output_column=\"pickup_segment\"\n",
    "    )\n",
    "    .with_mapping(\n",
    "        longitude_column=\"dropoff_longitude\",\n",
    "        latitude_column=\"dropoff_latitude\",\n",
    "        output_column=\"dropoff_segment\"\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Build loader with datetime parsing\n",
    "loader = (\n",
    "    mapper.loader\n",
    "    .from_file(\"./taxisvis5M_preprocessed.parquet\")\n",
    "    .with_columns(longitude_column=\"pickup_longitude\", latitude_column=\"pickup_latitude\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Build imputers for pickup and dropoff coordinates\n",
    "imputer_pickup = (\n",
    "    mapper.imputer\n",
    "    .with_type(\"SimpleGeoImputer\")\n",
    "    .on_columns(\"pickup_longitude\", \"pickup_latitude\")\n",
    "    .build()\n",
    ")\n",
    "imputer_dropoff = (\n",
    "    mapper.imputer\n",
    "    .with_type(\"SimpleGeoImputer\")\n",
    "    .on_columns(\"dropoff_longitude\", \"dropoff_latitude\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Build filter for bounding box\n",
    "filter_step = mapper.filter.with_type(\"BoundingBoxFilter\").build()\n",
    "\n",
    "# Build enrichers\n",
    "enrich_pickup_count = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\")\n",
    "    .count_by(output_column=\"pickup_count\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_dropoff_count = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"dropoff_segment\")\n",
    "    .count_by(output_column=\"dropoff_count\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_avg_fare = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\", values_from=\"fare_amount\")\n",
    "    .aggregate_by(method=average_fare_amount, output_column=\"avg_fare\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_avg_distance = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\", values_from=\"trip_distance\")\n",
    "    .aggregate_by(method=average_trip_distance, output_column=\"avg_distance\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_most_common_payment = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\", values_from=\"payment_type\")\n",
    "    .aggregate_by(method=most_common_payment, output_column=\"most_common_payment\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_peak_pickup_hour = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"pickup_segment\", values_from=\"tpep_pickup_datetime\")\n",
    "    .aggregate_by(method=peak_pickup_hour, output_column=\"peak_pickup_hour\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "enrich_peak_dropoff_hour = (\n",
    "    mapper.enricher\n",
    "    .with_data(group_by=\"dropoff_segment\", values_from=\"tpep_dropoff_datetime\")\n",
    "    .aggregate_by(method=peak_dropoff_hour, output_column=\"peak_dropoff_hour\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Build interactive visualiser with dark theme\n",
    "visualiser = (\n",
    "    mapper.visual\n",
    "    .with_type(\"Interactive\")\n",
    "    .with_style({\"tiles\": \"CartoDB dark_matter\"})\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = UrbanPipeline([\n",
    "    (\"urban_layer\", urban_layer),\n",
    "    (\"loader\", loader),\n",
    "    (\"impute_pickup\", imputer_pickup),\n",
    "    (\"impute_dropoff\", imputer_dropoff),\n",
    "    (\"filter\", filter_step),\n",
    "    (\"enrich_pickup_count\", enrich_pickup_count),\n",
    "    (\"enrich_dropoff_count\", enrich_dropoff_count),\n",
    "    (\"enrich_avg_fare\", enrich_avg_fare),\n",
    "    (\"enrich_avg_distance\", enrich_avg_distance),\n",
    "    (\"enrich_most_common_payment\", enrich_most_common_payment),\n",
    "    (\"enrich_peak_pickup_hour\", enrich_peak_pickup_hour),\n",
    "    (\"enrich_peak_dropoff_hour\", enrich_peak_dropoff_hour),\n",
    "    (\"visualiser\", visualiser)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sk/705pffl95sv3nzj0n2ls78cc0000gp/T/ipykernel_24381/2278523051.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  series = pd.to_datetime(series)\n",
      "/var/folders/sk/705pffl95sv3nzj0n2ls78cc0000gp/T/ipykernel_24381/2278523051.py:34: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  series = pd.to_datetime(series)\n"
     ]
    }
   ],
   "source": [
    "# Execute the pipeline\n",
    "mapped_data, enriched_layer = pipeline.compose_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c55bc53cd541429ab77075e4d304d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Column:', options=('pickup_count', 'dropoff_count', 'avg_fare', 'avg_dist…"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualise the enriched metrics\n",
    "fig = pipeline.visualise([\n",
    "    \"pickup_count\", \"dropoff_count\", \"avg_fare\", \"avg_distance\",\n",
    "    \"most_common_payment\", \"peak_pickup_hour\", \"peak_dropoff_hour\"\n",
    "])\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline\n",
    "pipeline.save(\"./taxi_advanced_pipeline.dill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the pipeline to JupyterGIS for collaborative exploration\n",
    "pipeline.to_jgis(\n",
    "    filepath=\"taxi_trips.JGIS\",\n",
    "    urban_layer_name=\"Taxi Trips Pickup and Dropoff analysis\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
