{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "This notebook demonstrates a streamlined UrbanMapper workflow using the `UrbanPipeline` class, replicating the step-by-step example with PLUTO data in `Downtown Brooklyn`. We’ll define all steps upfront, execute them in one go, and visualise the results.\n",
    "\n",
    "Essentially, this notebook covers the `Basics/[7]urban_pipeline.ipynb` example.\n",
    "\n",
    "**Data source used**:\n",
    "- PLUTO data from NYC Open Data. https://www.nyc.gov/content/planning/pages/resources/datasets/mappluto-pluto-change\n",
    "\n",
    "\n",
    "⚠️ Please Note — Within The Documentation's Interactive Examples ⚠️\n",
    "\n",
    "First and foremost, please bear with us; some of our Jupyter Notebooks cannot be interactive and are thus displayed as is in the documentation.  Feel free to install the library and test it out locally.  Next, determine whether they are interactive, which means you can see the output of each cell.  As a result, because it is not a good practice to save datasets in a GitHub (or any other Git in general) repository, we attempted to import urban datasets from `HuggingFace` using `from_huggingface(.)` rather than `from_file(.)`, which would need local file availability.  Nonetheless, this was (1) not always viable (certain datasets are not on `HuggingFace`), and (2) this does not preclude you from using `from_file(.)` or any other available via the API reference's `Loader` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urban_mapper import UrbanMapper\n",
    "from urban_mapper.pipeline import UrbanPipeline\n",
    "\n",
    "# Initialise UrbanMapper\n",
    "um = UrbanMapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: For the documentation interactive mode, we only query 5000 records from the dataset.  Feel free to remove for a more realistic analysis.\n",
    "data = (\n",
    "    UrbanMapper()\n",
    "    .loader\n",
    "    .from_huggingface(\"oscur/pluto\", number_of_rows=5000, streaming=True)\n",
    "    .with_columns(\"longitude\", \"latitude\")\n",
    "    .load()\n",
    ")\n",
    "\n",
    "data['longitude'] = data['longitude'].astype(float)\n",
    "data['latitude'] = data['latitude'].astype(float)\n",
    "\n",
    "data.to_csv(\"pluto.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Define the Pipeline\n",
    "\n",
    "**Goal**: Set up all components of the workflow in a single pipeline.\n",
    "\n",
    "**Input**: Configurations for each UrbanMapper module.\n",
    "\n",
    "**Output**: An `UrbanPipeline` object ready to process data.\n",
    "\n",
    "We define each step—urban layer, loader, imputer, filter, enricher, and visualiser—with their specific roles:\n",
    "- **Urban Layer**: Street intersections in Downtown Brooklyn.\n",
    "- **Loader**: PLUTO data from CSV.\n",
    "- **Imputer**: Fills missing coordinates.\n",
    "- **Filter**: Trims data to the bounding box.\n",
    "- **Enricher**: Adds average floors per intersection.\n",
    "- **Visualiser**: Prepares an interactive map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_layer = (\n",
    "    um.urban_layer.with_type(\"streets_intersections\")\n",
    "    .from_place(\"Downtown Brooklyn, New York City, USA\", network_type=\"drive\")\n",
    "    .with_mapping(\n",
    "        longitude_column=\"longitude\",\n",
    "        latitude_column=\"latitude\",\n",
    "        output_column=\"nearest_intersection\",\n",
    "        threshold_distance=50,\n",
    "    )  # Recall that with mapping is to tell `map_nearest_layer` how it should map the urban data with the urban layer.\n",
    "    .build()\n",
    ")\n",
    "\n",
    "loader = (\n",
    "    um.loader.from_file(\"./pluto.csv\").with_columns(\"longitude\", \"latitude\").build()\n",
    ")\n",
    "\n",
    "imputer = (\n",
    "    um.imputer.with_type(\"SimpleGeoImputer\").on_columns(\"longitude\", \"latitude\").build()\n",
    ")\n",
    "\n",
    "filter_step = um.filter.with_type(\"BoundingBoxFilter\").build()\n",
    "\n",
    "enricher = (\n",
    "    um.enricher.with_data(group_by=\"nearest_intersection\", values_from=\"numfloors\")\n",
    "    .aggregate_by(method=\"mean\", output_column=\"avg_floors\")\n",
    "    .build()\n",
    ")\n",
    "\n",
    "visualiser = (\n",
    "    um.visual.with_type(\"Interactive\")\n",
    "    .with_style({\"tiles\": \"CartoDB dark_matter\", \"colorbar_text_color\": \"white\"})\n",
    "    .build()\n",
    ")\n",
    "\n",
    "# Assemble the pipeline\n",
    "pipeline = UrbanPipeline(\n",
    "    [\n",
    "        (\"urban_layer\", urban_layer),\n",
    "        (\"loader\", loader),\n",
    "        (\"imputer\", imputer),\n",
    "        (\"filter\", filter_step),\n",
    "        (\"enricher\", enricher),\n",
    "        (\"visualiser\", visualiser),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Let's preview the urban pipeline we just created\n",
    "pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Execute the Pipeline\n",
    "\n",
    "**Goal**: Process the data through all defined steps in one operation.\n",
    "\n",
    "**Input**: The `UrbanPipeline` object from Step 1.\n",
    "\n",
    "**Output**: A mapped GeoDataFrame and an enriched `UrbanLayer` with processed data.\n",
    "\n",
    "The `compose_transform` method runs the entire workflow—loading data, imputing, filtering, mapping, and enriching—in a single call, ensuring seamless data flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_data, enriched_layer = pipeline.compose_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Visualise Results\n",
    "\n",
    "**Goal**: Present the enriched data on an interactive map.\n",
    "\n",
    "**Input**: The enriched layer from Step 2 and columns to display (`avg_floors`).\n",
    "\n",
    "**Output**: An interactive Folium map showing average floors per intersection.\n",
    "\n",
    "The pipeline’s `visualise` method leverages the pre-configured visualiser to generate the map directly from the enriched layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = pipeline.visualise([\"avg_floors\"])\n",
    "fig  # Display the interactive map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Save and Load Pipeline\n",
    "\n",
    "**Goal**: Preserve the pipeline for future use or sharing.\n",
    "\n",
    "**Input**: A file path (`./my_pipeline.dill`) for saving.\n",
    "\n",
    "**Output**: A saved pipeline file and a reloaded `UrbanPipeline` object.\n",
    "\n",
    "Saving with `save` and loading with `load` allows you to reuse or distribute your workflow effortlessly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the pipeline\n",
    "pipeline.save(\"./my_pipeline.dill\")\n",
    "\n",
    "# Load it back\n",
    "loaded_pipeline = UrbanPipeline.load(\"./my_pipeline.dill\")\n",
    "\n",
    "# Preview the loaded pipeline\n",
    "loaded_pipeline.preview()\n",
    "\n",
    "# Visualise with the loaded pipeline\n",
    "fig = loaded_pipeline.visualise([\"avg_floors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Well done! Using `UrbanPipeline`, you’ve efficiently processed and visualised PLUTO data with less code than the step-by-step approach. This method shines for its simplicity and reusability. Compare it with the Step-by-Step notebook for a detailed breakdown of each stage!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
