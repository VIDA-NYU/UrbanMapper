{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Urban Pipeline \n",
    "\n",
    "In this notebook, we'll show how to go from step by step, that is notebook `[1-6]` by bundling up all your workflow steps into one neat pipeline.\n",
    "\n",
    "**Data source used**:\n",
    "- PLUTO data from NYC Open Data. https://www.nyc.gov/content/planning/pages/resources/datasets/mappluto-pluto-change\n",
    "\n",
    "Letâ€™s get started! ðŸŒŸ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urban_mapper as um\n",
    "from urban_mapper.pipeline import UrbanPipeline\n",
    "\n",
    "mapper = um.UrbanMapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Whatâ€™s the `UrbanPipeline` All About?\n",
    "\n",
    "The `UrbanPipeline` class is like the conductor of an orchestra â€“â€“ for the ML enthusiasts, it is trying to mimic what Scikit-Learn does with the Scikit Pipeline â€“â€“ â€”it brings together all the UrbanMapper steps (loading data, creating layers, imputing missing bits, filtering, enriching, and visualising) and makes them play in harmony. You define your steps, pop them into the pipeline, and it handles the rest. Itâ€™s brilliant for keeping your workflow tidy and repeatable; yet not only, also shareable and reusable!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting Up a Simple Pipeline\n",
    "\n",
    "Letâ€™s build a pipeline that does the following:\n",
    "\n",
    "- Loads PLUTO data from a CSV file.\n",
    "- Creates a street intersections layer for Manhattan.\n",
    "- Imputes missing coordinates.\n",
    "- Filters data to the layerâ€™s bounding box.\n",
    "- Enriches the layer with average building floors.\n",
    "- Sets up an interactive map to visualise it all.\n",
    "\n",
    "Weâ€™ll define each step and slot them into our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_layer = (\n",
    "    mapper.urban_layer.with_type(\"streets_intersections\")\n",
    "    .from_place(\"Manhattan, New York City, USA\", network_type=\"drive\")\n",
    "    # With mapping is the equivalent of map_nearest_layer, yet this one below is prepping how should the map_nearest_layer be done by UrbanMpapper under the hood.\n",
    "    .with_mapping(\n",
    "        longitude_column=\"longitude\", latitude_column=\"latitude\",\n",
    "#        geometry_column=<geometry_column_name>\", # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.    \n",
    "        output_column=\"nearest_intersection\",\n",
    "        threshold_distance=50,  # Optional: sets a 50-meter threshold for nearest mapping.\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "# Note: For the documentation interactive mode, we only query 100000 records from the dataset.  Feel free to remove for a more realistic analysis.\n",
    "loader = (\n",
    "  mapper\n",
    "  .loader\n",
    "  .from_huggingface(\"oscur/pluto\", number_of_rows=100000, streaming=True)\n",
    "  .with_columns(\"longitude\", \"latitude\")\n",
    "#  .with_columns(geometry_column=<geometry_column_name>\") # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.      \n",
    "  .build()\n",
    ")\n",
    "imputer = (\n",
    "  mapper\n",
    "  .imputer\n",
    "  .with_type(\"SimpleGeoImputer\")\n",
    "  .on_columns(\"longitude\", \"latitude\")\n",
    "#  .on_columns(geometry_column=<geometry_column_name>\") # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.      \n",
    "  .build()\n",
    ")\n",
    "filter_step = mapper.filter.with_type(\"BoundingBoxFilter\").build()\n",
    "enricher = mapper.enricher.with_data(group_by=\"nearest_intersection\", values_from=\"numfloors\").aggregate_by(method=\"mean\", output_column=\"avg_floors\").build()\n",
    "visualiser = mapper.visual.with_type(\"Interactive\").with_style({\"tiles\": \"CartoDB Positron\", \"colorbar_text_color\": \"gray\"}).build()\n",
    "\n",
    "# Assemble the pipeline\n",
    "# Note that a pipeline's step is a tuple with a name and the step itself.\n",
    "# Later one when loading the pipeline, or sharing it, anyone can use `.get_step(\"step_name\")` to get the step, preview it, re-run it, etc.\n",
    "pipeline = UrbanPipeline(\n",
    "    [\n",
    "        (\"urban_layer\", urban_layer),\n",
    "        (\"loader\", loader),\n",
    "        (\"imputer\", imputer),\n",
    "        (\"filter\", filter_step),\n",
    "        (\"enricher\", enricher),\n",
    "        (\"visualiser\", visualiser)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Note that we can do this in a more concise way, but we are showing the steps for clarity.\n",
    "# The concise way would be looking alike this for only with urban layer:\n",
    "\n",
    "# pipeline = UrbanPipeline([\n",
    "#     (\"urban_layer\", (\n",
    "#         mapper.urban_layer\n",
    "#         .with_type(\"streets_intersections\")\n",
    "#         .from_place(\"Downtown Brooklyn, New York City, USA\", network_type=\"drive\")\n",
    "#         .with_mapping(\n",
    "#             longitude_column=\"longitude\",\n",
    "#             latitude_column=\"latitude\",\n",
    "##             geometry_column=<geometry_column_name>\", # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.  \n",
    "#             output_column=\"nearest_intersection\",\n",
    "#             threshold_distance=50\n",
    "#         )\n",
    "#         .build()\n",
    "#     )),\n",
    "#     # Add the other steps here\n",
    "# ])\n",
    "\n",
    "# Let's preview our urban pipeline workflow\n",
    "pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Pipeline\n",
    "\n",
    "Time to put it to work! Weâ€™ll use `compose_transform` to run the entire pipeline in one goâ€”loading, imputing, filtering, mapping, enriching, all sorted. Then, weâ€™ll visualise the results with a snazzy interactive map.\n",
    "\n",
    "Note however that we could do this in two steps, first calling `compose()` and then `transform()`, but we are showing the two steps in one for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the pipeline\n",
    "mapped_data, enriched_layer = pipeline.compose_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the results\n",
    "fig = pipeline.visualise(result_columns=[\"avg_floors\"])\n",
    "# result_columns is basically the columns that will be displayed in the map.\n",
    "# If you want to display only one column, you can pass a string as well.\n",
    "\n",
    "fig  # Displays an interactive map in your notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and Loading Your Pipeline\n",
    "\n",
    "You can save your pipeline to a file and load it back later (that means every you would need the pipeline, it won't need to redo its entire workflow as saved). Here, weâ€™ll save it, load it, and ensure itâ€™s ready for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.save(\"./my_pipeline.dill\")\n",
    "\n",
    "loaded_pipeline = UrbanPipeline.load(\"./my_pipeline.dill\")\n",
    "\n",
    "loaded_pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing the Enriched Layer for Machine Learning Analysis\n",
    "\n",
    "Now, letâ€™s retrieve the enriched urban layer using `.get_layer()` for machine learning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enriched_layer = loaded_pipeline.get_step(\"urban_layer\")\n",
    "\n",
    "enriched_gdf = enriched_layer.get_layer()\n",
    "\n",
    "enriched_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load many different datasets in the same pipeline\n",
    "\n",
    "You can load many datasets. All the provided datasets should have the same columns provided in `with_data`, `aggregate_by`, etc.\n",
    "\n",
    "The static visualizer looks into the enriched data with `data_id` column and uses it to show data with different markers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urban_layer = (\n",
    "    mapper.urban_layer.with_type(\"streets_intersections\")\n",
    "    .from_place(\"Manhattan, New York City, USA\", network_type=\"drive\")\n",
    "    # With mapping is the equivalent of map_nearest_layer, yet this one below is prepping how should the map_nearest_layer be done by UrbanMpapper under the hood.\n",
    "    .with_mapping(\n",
    "        longitude_column=\"longitude\",\n",
    "        latitude_column=\"latitude\",\n",
    "#        geometry_column=<geometry_column_name>\", # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.      \n",
    "        output_column=\"nearest_intersection\",\n",
    "        threshold_distance=50,  # Optional: sets a 50-meter threshold for nearest mapping.\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "loader1 = (\n",
    "  mapper\n",
    "  .loader\n",
    "  .from_huggingface(\"oscur/pluto\", number_of_rows=1000, streaming=True)\n",
    "  .with_columns(\"longitude\", \"latitude\")\n",
    "#  .with_columns(geometry_column=<geometry_column_name>\") # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.        \n",
    "  .build()\n",
    ")\n",
    "loader2 = (\n",
    "  mapper\n",
    "  .loader\n",
    "  .from_huggingface(\"oscur/taxisvis1M\", number_of_rows=1000, streaming=True)\n",
    "  .with_columns(\"pickup_longitude\", \"pickup_latitude\")\n",
    "  .with_map({\"pickup_longitude\": \"longitude\", \"pickup_latitude\": \"latitude\"})\n",
    "#  .with_columns(geometry_column=<geometry_column_name>\") # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.        \n",
    "  .build()\n",
    ")\n",
    "\n",
    "# Both imputer and filter will be applied only to loader2\n",
    "imputer = (\n",
    "  mapper\n",
    "  .imputer\n",
    "  .with_data(\"taxi_data\")\n",
    "  .with_type(\"SimpleGeoImputer\")\n",
    "  .on_columns(\"longitude\", \"latitude\")\n",
    "#   .on_columns(geometry_column=<geometry_column_name>\") # Replace <geometry_column_name> with the actual name of your geometry column instead of latitude and longitude columns.        \n",
    "  .build()\n",
    ")\n",
    "filter_step = mapper.filter.with_data(\"taxi_data\").with_type(\"BoundingBoxFilter\").build()\n",
    "\n",
    "# Enricher will be applied to the dataset\n",
    "enricher1 = mapper.enricher.with_data(group_by=\"nearest_intersection\", values_from=\"numfloors\", data_id=\"pluto_data\").aggregate_by(method=\"mean\", output_column=\"avg_floors\").build()\n",
    "enricher2 = mapper.enricher.with_data(group_by=\"pickup_segment\", data_id=\"taxi_data\").count_by(output_column=\"pickup_count\").build()\n",
    "\n",
    "visualiser = mapper.visual.with_type(\"Interactive\").with_style({\"tiles\": \"CartoDB Positron\", \"colorbar_text_color\": \"gray\"}).build()\n",
    "\n",
    "# Assemble the pipeline\n",
    "# Note that a pipeline's step is a tuple with a name and the step itself.\n",
    "# When more than one loader is defined, the pipeline creates a dictonary with all the loaded data and the step loader names as keys\n",
    "# Later one when loading the pipeline, or sharing it, anyone can use `.get_step(\"step_name\")` to get the step, preview it, re-run it, etc.\n",
    "pipeline = UrbanPipeline(\n",
    "    [\n",
    "        (\"urban_layer\", urban_layer),\n",
    "        (\"pluto_data\", loader1),\n",
    "        (\"taxi_data\", loader2),\n",
    "        (\"imputer\", imputer),\n",
    "        (\"filter\", filter_step),\n",
    "        (\"enricher1\", enricher1),\n",
    "        (\"enricher2\", enricher2),\n",
    "        (\"visualiser\", visualiser)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Let's preview our urban pipeline workflow\n",
    "pipeline.preview()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceeding with Machine Learning Analysis\n",
    "\n",
    "With the enriched layer in hand, letâ€™s perform a simple machine learning task. Weâ€™ll use K-Means clustering to group street intersections based on the average number of building floors (`avg_floors`).\n",
    "\n",
    "### Step 1: Prepare the Data\n",
    "\n",
    "Extract the relevant feature from the enriched layer and handle any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = enriched_gdf[['avg_floors']]\n",
    "\n",
    "features = features.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Apply K-Means Clustering\n",
    "\n",
    "Cluster the intersections into 3 groups based on `avg_floors`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "kmeans.fit(features)\n",
    "\n",
    "enriched_gdf['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Visualise the Clusters\n",
    "\n",
    "Visualise the clusters on a static map using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract the cluster centroids (average floors for each cluster) and flatten to 1D\n",
    "centroids = kmeans.cluster_centers_.flatten()\n",
    "\n",
    "# Get the indices that would sort the centroids from low to high\n",
    "sorted_indices = np.argsort(centroids)\n",
    "\n",
    "# Create a mapping from original cluster labels to new sorted labels\n",
    "label_mapping = {original: new for new, original in enumerate(sorted_indices)}\n",
    "\n",
    "# Apply the mapping to the GeoDataFrame to create sorted cluster labels\n",
    "enriched_gdf['cluster_sorted'] = enriched_gdf['cluster'].map(label_mapping)\n",
    "\n",
    "# Round the sorted centroids for display in the legend\n",
    "rounded_centroids = [round(centroids[idx], 1) for idx in sorted_indices]\n",
    "\n",
    "# Set up the figure and axis for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Plot the GeoDataFrame using the sorted cluster labels and 'viridis' colormap\n",
    "scatter = enriched_gdf.plot(column='cluster_sorted', ax=ax, cmap='viridis')\n",
    "\n",
    "# Label the axes and set the title\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "plt.title('Street Intersections in Manhattan Clustered by Average Building Floors')\n",
    "\n",
    "# Add a color bar to the plot\n",
    "cbar = scatter.get_figure().colorbar(scatter.get_children()[0], ax=ax)\n",
    "\n",
    "# Set the ticks and labels for the color bar based on the sorted centroids\n",
    "cbar.set_ticks(range(len(sorted_indices)))\n",
    "cbar.set_ticklabels([f'Avg. Floors: {centroid}' for centroid in rounded_centroids])\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting to JupyterGIS (Optional)\n",
    "\n",
    "For collaborative exploration, you can export your pipeline to JupyterGIS. Check out [JupyterGIS documentation](https://github.com/geojupyter/jupytergis) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.to_jgis(\n",
    "    filepath=\"urban_analysis.JGIS\",\n",
    "    urban_layer_name=\"Manhattan Intersections\",\n",
    "    raise_on_existing=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapping It Up\n",
    "\n",
    "Smashing job! ðŸŒŸ Youâ€™ve built and run your first `UrbanPipeline`, saved it, loaded it back, retrieved the enriched layer, and performed a machine learning analysis. You can now reuse, share, or tweak this workflow as needed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
